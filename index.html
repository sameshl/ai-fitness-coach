<!DOCTYPE html>
<html lang="en">
  <head>
    <title>HeyGen Streaming API LiveKit (V2)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/livekit-client/dist/livekit-client.umd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="Permissions-Policy" content="camera=*, microphone=*" />
    <style>
      .video-container {
        position: relative;
        display: block;
        margin-bottom: 10px;
      }
      .pose-canvas {
        position: absolute;
        top: 0;
        left: 0;
        z-index: 10;
      }

      /* Make sure inputs and buttons stack nicely on mobile */
      @media (max-width: 768px) {
        .flex-wrap > * {
          min-width: 100%;
        }
      }
    </style>
  </head>

  <body class="bg-gray-100 p-5 font-sans">
    <div class="max-w-3xl mx-auto bg-white p-5 rounded-lg shadow-md">
      <div class="flex flex-wrap gap-2.5 mb-5">
        <input
          id="avatarID"
          type="text"
          placeholder="Avatar ID"
          class="flex-1 min-w-[200px] p-2 border border-gray-300 rounded-md"
        />
        <input
          id="voiceID"
          type="text"
          placeholder="Voice ID"
          class="flex-1 min-w-[200px] p-2 border border-gray-300 rounded-md"
        />
        <button
          id="startBtn"
          class="px-4 py-2 bg-green-500 text-white rounded-md hover:bg-green-600 transition-colors disabled:opacity-50 disabled:cursor-not-allowed"
        >
          Start
        </button>
        <button
          id="closeBtn"
          class="px-4 py-2 bg-red-500 text-white rounded-md hover:bg-red-600 transition-colors"
        >
          Close
        </button>
      </div>

      <div class="flex flex-wrap gap-2.5 mb-5">
        <input
          id="taskInput"
          type="text"
          placeholder="Enter text for avatar to speak"
          class="flex-1 min-w-[200px] p-2 border border-gray-300 rounded-md"
        />
        <button
          id="talkBtn"
          class="px-4 py-2 bg-green-500 text-white rounded-md hover:bg-green-600 transition-colors"
        >
          Talk (LLM)
        </button>
        <button
          id="repeatBtn"
          class="px-4 py-2 bg-blue-500 text-white rounded-md hover:bg-blue-600 transition-colors"
        >
          Repeat
        </button>
      </div>

      <div class="flex flex-wrap gap-2.5 mb-5">
        <button
          id="cameraPermissionBtn"
          class="px-4 py-2 bg-blue-500 text-white rounded-md hover:bg-blue-600 transition-colors"
        >
          Enable Camera
        </button>
      </div>

      <div class="flex flex-col md:flex-row gap-4 mb-5">
        <div class="video-container w-full md:w-1/2">
          <video
            id="mediaElement"
            class="w-full aspect-video border rounded-lg"
            autoplay
          ></video>
        </div>

        <div class="video-container w-full md:w-1/2">
          <video
            id="poseVideo"
            class="w-full aspect-video border rounded-lg"
            autoplay
          ></video>
          <canvas id="poseCanvas" class="pose-canvas w-full h-full"></canvas>
        </div>
      </div>
      <div
        id="status"
        class="p-2.5 bg-gray-50 border border-gray-300 rounded-md h-[100px] overflow-y-auto font-mono text-sm"
      ></div>

      <div class="flex gap-2 mt-4">
        <button
          id="recordButton"
          class="px-4 py-2 bg-purple-500 text-white rounded-md hover:bg-purple-600 transition-colors hidden"
        >
          Start Recording
        </button>
        <button
          id="downloadButton"
          class="px-4 py-2 bg-gray-500 text-white rounded-md hover:bg-gray-600 transition-colors hidden"
          disabled
        >
          Download Recording
        </button>
        <button
          id="downloadPromptsBtn"
          class="px-4 py-2 bg-yellow-500 text-white rounded-md hover:bg-yellow-600 transition-colors hidden"
        >
          Download Prompts
        </button>
      </div>
    </div>

    <script>
      // Configuration
      const API_CONFIG = {
        apiKey: "MWJjNWU3NzkzMzY2NGQ1ZTkzNjY0YzYxODJhOTljMzAtMTczNzg0MjQxOQ==",
        serverUrl: "https://api.heygen.com",
      };

      // Global variables
      let sessionInfo = null;
      let room = null;
      let mediaStream = null;
      let webSocket = null;
      let sessionToken = null;
      let poseDetector = null;
      let poseVideo = null;
      let poseCanvas = null;
      let poseCtx = null;
      let isRecording = false;
      let recordedPoses = [];
      let lastRecordedTime = 0;
      let exerciseBuffer = [];
      const BUFFER_SIZE = 3;
      let cameraStream = null;
      let lastRepTime = 0;
      const REP_COOLDOWN = 4000; // Changed from 4000ms to 2000ms (2 seconds)
      const FRAMES_PER_REP = 20; // Changed from 40 to 20 frames (2 seconds at 10fps)
      let savedPrompts = [];
      let recordingStartTimeout = null;

      // DOM Elements
      const statusElement = document.getElementById("status");
      const mediaElement = document.getElementById("mediaElement");
      const avatarID = document.getElementById("avatarID");
      const voiceID = document.getElementById("voiceID");
      const taskInput = document.getElementById("taskInput");

      // Helper function to update status
      function updateStatus(message) {
        const timestamp = new Date().toLocaleTimeString();
        statusElement.innerHTML += `[${timestamp}] ${message}<br>`;
        statusElement.scrollTop = statusElement.scrollHeight;
      }

      // Get session token
      async function getSessionToken() {
        const response = await fetch(
          `${API_CONFIG.serverUrl}/v1/streaming.create_token`,
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              "X-Api-Key": API_CONFIG.apiKey,
            },
          }
        );

        const data = await response.json();
        sessionToken = data.data.token;
        updateStatus("Session token obtained");
      }

      // Connect WebSocket
      async function connectWebSocket(sessionId) {
        const params = new URLSearchParams({
          session_id: sessionId,
          session_token: sessionToken,
          silence_response: false,
          opening_text: "Hello, how can I help you?",
          stt_language: "en",
        });

        const wsUrl = `wss://${
          new URL(API_CONFIG.serverUrl).hostname
        }/v1/ws/streaming.chat?${params}`;

        webSocket = new WebSocket(wsUrl);

        // Handle WebSocket events
        webSocket.addEventListener("message", (event) => {
          const eventData = JSON.parse(event.data);
          console.log("Raw WebSocket event:", eventData);
        });
      }

      // Create new session
      async function createNewSession() {
        if (!sessionToken) {
          await getSessionToken();
        }

        const response = await fetch(
          `${API_CONFIG.serverUrl}/v1/streaming.new`,
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${sessionToken}`,
            },
            body: JSON.stringify({
              quality: "high",
              avatar_name: avatarID.value,
              voice: {
                voice_id: voiceID.value,
              },
              version: "v2",
              video_encoding: "H264",
            }),
          }
        );

        const data = await response.json();
        sessionInfo = data.data;

        // Create LiveKit Room
        room = new LivekitClient.Room({
          adaptiveStream: true,
          dynacast: true,
          videoCaptureDefaults: {
            resolution: LivekitClient.VideoPresets.h720.resolution,
          },
        });

        // Handle room events
        room.on(LivekitClient.RoomEvent.DataReceived, (message) => {
          const data = new TextDecoder().decode(message);
          console.log("Room message:", JSON.parse(data));
        });

        // Handle media streams
        mediaStream = new MediaStream();
        room.on(LivekitClient.RoomEvent.TrackSubscribed, (track) => {
          if (track.kind === "video" || track.kind === "audio") {
            mediaStream.addTrack(track.mediaStreamTrack);
            if (
              mediaStream.getVideoTracks().length > 0 &&
              mediaStream.getAudioTracks().length > 0
            ) {
              mediaElement.srcObject = mediaStream;
              updateStatus("Media stream ready");
            }
          }
        });

        // Handle media stream removal
        room.on(LivekitClient.RoomEvent.TrackUnsubscribed, (track) => {
          const mediaTrack = track.mediaStreamTrack;
          if (mediaTrack) {
            mediaStream.removeTrack(mediaTrack);
          }
        });

        // Handle room connection state changes
        room.on(LivekitClient.RoomEvent.Disconnected, (reason) => {
          updateStatus(`Room disconnected: ${reason}`);
        });

        await room.prepareConnection(sessionInfo.url, sessionInfo.access_token);
        updateStatus("Connection prepared");

        // Connect WebSocket after room preparation
        await connectWebSocket(sessionInfo.session_id);

        updateStatus("Session created successfully");
      }

      // Start streaming session
      async function startStreamingSession() {
        try {
          // Initialize pose detection first
          await initPoseDetection();

          // Then start HeyGen stream
          const startResponse = await fetch(
            `${API_CONFIG.serverUrl}/v1/streaming.start`,
            {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
                Authorization: `Bearer ${sessionToken}`,
              },
              body: JSON.stringify({
                session_id: sessionInfo.session_id,
              }),
            }
          );

          await room.connect(sessionInfo.url, sessionInfo.access_token);
          updateStatus("Connected to room");

          document.querySelector("#startBtn").disabled = true;
          updateStatus("Streaming started successfully");
          showRecordingButtons();
        } catch (error) {
          updateStatus(`Error starting session: ${error.message}`);
          console.error("Session start error:", error);
        }
      }

      // Send text to avatar
      async function sendText(text, taskType = "talk") {
        if (!sessionInfo) {
          updateStatus("No active session");
          return;
        }

        const response = await fetch(
          `${API_CONFIG.serverUrl}/v1/streaming.task`,
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${sessionToken}`,
            },
            body: JSON.stringify({
              session_id: sessionInfo.session_id,
              text: text,
              task_type: taskType,
            }),
          }
        );

        updateStatus(`Sent text (${taskType}): ${text}`);
      }

      // Close session
      async function closeSession() {
        if (!sessionInfo) {
          updateStatus("No active session");
          return;
        }

        const response = await fetch(
          `${API_CONFIG.serverUrl}/v1/streaming.stop`,
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${sessionToken}`,
            },
            body: JSON.stringify({
              session_id: sessionInfo.session_id,
            }),
          }
        );

        // Close WebSocket
        if (webSocket) {
          webSocket.close();
        }
        // Disconnect from LiveKit room
        if (room) {
          room.disconnect();
        }

        mediaElement.srcObject = null;
        sessionInfo = null;
        room = null;
        mediaStream = null;
        sessionToken = null;
        document.querySelector("#startBtn").disabled = false;

        updateStatus("Session closed");

        if (recordingStartTimeout) {
          clearTimeout(recordingStartTimeout);
          recordingStartTimeout = null;
        }
      }

      // Event Listeners
      document
        .querySelector("#startBtn")
        .addEventListener("click", async () => {
          try {
            if (!cameraStream) {
              updateStatus("Please enable camera access first");
              return;
            }
            await createNewSession();
            await startStreamingSession();
          } catch (error) {
            updateStatus(`Failed to start session: ${error.message}`);
            console.error("Start session error:", error);
          }
        });
      document
        .querySelector("#closeBtn")
        .addEventListener("click", closeSession);
      document.querySelector("#talkBtn").addEventListener("click", () => {
        const text = taskInput.value.trim();
        if (text) {
          sendText(text, "talk");
          taskInput.value = "";
        }
      });
      document.querySelector("#repeatBtn").addEventListener("click", () => {
        const text = taskInput.value.trim();
        if (text) {
          sendText(text, "repeat");
          taskInput.value = "";
        }
      });

      // Add these functions before the event listeners
      async function initPoseDetection() {
        poseVideo = document.getElementById("poseVideo");
        poseCanvas = document.getElementById("poseCanvas");
        poseCtx = poseCanvas.getContext("2d");

        const resizeCanvas = () => {
          poseCanvas.width = poseVideo.clientWidth;
          poseCanvas.height = poseVideo.clientHeight;
        };

        resizeCanvas();
        window.addEventListener("resize", resizeCanvas);

        try {
          // Use the existing camera stream
          if (!cameraStream) {
            throw new Error("Camera permission not granted");
          }

          poseVideo.srcObject = cameraStream;
          await new Promise((resolve) => {
            poseVideo.onloadedmetadata = () => resolve();
          });
          await poseVideo.play();

          poseDetector = await poseDetection.createDetector(
            poseDetection.SupportedModels.MoveNet
          );

          detectPose();
        } catch (error) {
          console.error("Error in pose detection setup:", error);
          updateStatus(`Camera setup error: ${error.message}`);
          throw error;
        }
      }

      // Update the checkCameraPermissions function
      async function checkCameraPermissions() {
        try {
          // On mobile, we need to directly try getting the stream
          const stream = await navigator.mediaDevices.getUserMedia({
            video: {
              facingMode: "user",
              width: { ideal: 1280 },
              height: { ideal: 720 },
            },
          });

          // Keep this stream alive - don't stop it
          // We'll use it in initPoseDetection
          return stream;
        } catch (err) {
          console.error("Camera permission error:", err);
          return null;
        }
      }

      function getAngleBetweenPoints(a, b, c) {
        const vectorAB = {
          x: b.x - a.x,
          y: b.y - a.y,
        };
        const vectorBC = {
          x: c.x - b.x,
          y: c.y - b.y,
        };

        const dotProduct = vectorAB.x * vectorBC.x + vectorAB.y * vectorBC.y;
        const magnitudeAB = Math.sqrt(
          vectorAB.x * vectorAB.x + vectorAB.y * vectorAB.y
        );
        const magnitudeBC = Math.sqrt(
          vectorBC.x * vectorBC.x + vectorBC.y * vectorBC.y
        );
        const angleRadians = Math.acos(
          dotProduct / (magnitudeAB * magnitudeBC)
        );
        return 180 - (angleRadians * 180) / Math.PI;
      }

      async function analyzePose(poses) {
        if (!poses.length) return null;

        const pose = poses[0];
        const kp = Object.fromEntries(
          pose.keypoints.filter((k) => k.score > 0.5).map((k) => [k.name, k])
        );

        const angles = {};
        const analysis = {};

        // Calculate midpoints with null checks
        const shoulderMidpoint =
          kp.left_shoulder && kp.right_shoulder
            ? {
                x: (kp.left_shoulder.x + kp.right_shoulder.x) / 2,
                y: (kp.left_shoulder.y + kp.right_shoulder.y) / 2,
              }
            : null;

        const hipMidpoint =
          kp.left_hip && kp.right_hip
            ? {
                x: (kp.left_hip.x + kp.right_hip.x) / 2,
                y: (kp.left_hip.y + kp.right_hip.y) / 2,
              }
            : null;

        const ankleMidpoint =
          kp.left_ankle && kp.right_ankle
            ? {
                x: (kp.left_ankle.x + kp.right_ankle.x) / 2,
                y: (kp.left_ankle.y + kp.right_ankle.y) / 2,
              }
            : null;

        // 1. Pushup-specific measurements
        analysis.pushup = {};

        // Body alignment with null check
        if (shoulderMidpoint && hipMidpoint && ankleMidpoint) {
          const angle = getAngleBetweenPoints(
            shoulderMidpoint,
            hipMidpoint,
            ankleMidpoint
          );
          if (!isNaN(angle)) analysis.pushup.plankAlignment = angle;
        }

        // Height with null check
        if (kp.left_shoulder && kp.right_shoulder) {
          const height = Math.min(kp.left_shoulder.y, kp.right_shoulder.y);
          if (!isNaN(height)) analysis.pushup.height = height;
        }

        // Format the prompt data, filtering out undefined/NaN values
        const promptData = {
          timestamp: Date.now(),
          analysis: {
            pushup: Object.entries(analysis.pushup)
              .filter(
                ([_, v]) =>
                  v != null &&
                  (typeof v === "number"
                    ? !isNaN(v)
                    : Object.values(v).every((x) => !isNaN(x)))
              )
              .reduce((acc, [k, v]) => ({ ...acc, [k]: v }), {}),
          },
          keypoints: Object.values(kp)
            .filter(
              (point) =>
                point &&
                !isNaN(point.x) &&
                !isNaN(point.y) &&
                !isNaN(point.score)
            )
            .map((point) => ({
              name: point.name,
              x: point.x,
              y: point.y,
              score: point.score,
            })),
        };

        return promptData;
      }

      // Modify the detectPose function to include recording logic
      async function detectPose() {
        if (!poseDetector) return;

        const poses = await poseDetector.estimatePoses(poseVideo);

        poseCtx.clearRect(0, 0, poseCanvas.width, poseCanvas.height);

        poses.forEach((pose) => {
          // Draw keypoints
          pose.keypoints.forEach((keypoint) => {
            if (keypoint.score > 0.5) {
              poseCtx.beginPath();
              poseCtx.arc(
                (keypoint.x * poseCanvas.width) / poseVideo.videoWidth,
                (keypoint.y * poseCanvas.height) / poseVideo.videoHeight,
                5,
                0,
                2 * Math.PI
              );
              poseCtx.fillStyle = "red";
              poseCtx.fill();
            }
          });

          // Draw skeleton
          const connections = [
            ["left_shoulder", "right_shoulder"],
            ["left_hip", "right_hip"],
            ["left_shoulder", "left_hip"],
            ["right_shoulder", "right_hip"],
            ["left_shoulder", "left_elbow"],
            ["right_shoulder", "right_elbow"],
            ["left_elbow", "left_wrist"],
            ["right_elbow", "right_wrist"],
            ["left_hip", "left_knee"],
            ["right_hip", "right_knee"],
            ["left_knee", "left_ankle"],
            ["right_knee", "right_ankle"],
          ];

          poseCtx.strokeStyle = "blue";
          poseCtx.lineWidth = 2;

          connections.forEach(([from, to]) => {
            const fromPoint = pose.keypoints.find((kp) => kp.name === from);
            const toPoint = pose.keypoints.find((kp) => kp.name === to);

            if (
              fromPoint &&
              toPoint &&
              fromPoint.score > 0.5 &&
              toPoint.score > 0.5
            ) {
              poseCtx.beginPath();
              poseCtx.moveTo(
                (fromPoint.x * poseCanvas.width) / poseVideo.videoWidth,
                (fromPoint.y * poseCanvas.height) / poseVideo.videoHeight
              );
              poseCtx.lineTo(
                (toPoint.x * poseCanvas.width) / poseVideo.videoWidth,
                (toPoint.y * poseCanvas.height) / poseVideo.videoHeight
              );
              poseCtx.stroke();
            }
          });
        });

        if (isRecording) {
          const currentTime = Date.now();
          // Keep 10fps recording rate (100ms instead of 50ms)
          if (currentTime - lastRecordedTime >= 100) {
            const analysis = await analyzePose(poses);
            if (analysis) {
              recordedPoses.push(analysis);
              if (recordedPoses.length > FRAMES_PER_REP) {
                recordedPoses.shift();
              }

              // Send to LLM every 2 seconds
              if (currentTime - lastRepTime >= REP_COOLDOWN) {
                const prompt = `
Last 2 seconds of movement (10fps):
${recordedPoses
  .map(
    (frame, i) => `
Frame ${i + 1}:
Plank: ${frame.analysis.pushup.plankAlignment?.toFixed(1)}Â°
Height: ${frame.analysis.pushup.height?.toFixed(1)}
`
  )
  .join("\n")}
`;

                // Save prompt with timestamp
                savedPrompts.push({
                  timestamp: new Date().toISOString(),
                  prompt: prompt,
                });

                // Get response from Claude first
                const claudeResponse = await getClaudeResponse(prompt);

                if (claudeResponse) {
                  // Send Claude's response to HeyGen
                  await sendText(claudeResponse, "repeat");
                }

                lastRepTime = currentTime;
              }
              lastRecordedTime = currentTime;
            }
          }
        }

        requestAnimationFrame(detectPose);
      }

      // Add these to your existing startStreamingSession function
      function showRecordingButtons() {
        document.getElementById("recordButton").classList.remove("hidden");
        document.getElementById("downloadButton").classList.remove("hidden");
        document
          .getElementById("downloadPromptsBtn")
          .classList.remove("hidden");
      }

      // Update the record button click handler
      document.getElementById("recordButton").addEventListener("click", () => {
        const recordButton = document.getElementById("recordButton");
        const downloadButton = document.getElementById("downloadButton");
        const downloadPromptsBtn =
          document.getElementById("downloadPromptsBtn");

        if (!isRecording) {
          // Start recording after 2 second delay
          recordButton.textContent = "Stop Recording";
          recordButton.classList.replace("bg-purple-500", "bg-red-500");
          recordButton.classList.replace(
            "hover:bg-purple-600",
            "hover:bg-red-600"
          );
          downloadButton.disabled = true;
          downloadPromptsBtn.disabled = true;

          recordingStartTimeout = setTimeout(() => {
            isRecording = true;
            recordedPoses = [];
            lastRecordedTime = 0;
            lastRepTime = 0;
          }, 2000);
        } else {
          // Stop recording immediately
          if (recordingStartTimeout) {
            clearTimeout(recordingStartTimeout);
            recordingStartTimeout = null;
          }
          isRecording = false;
          recordButton.textContent = "Start Recording";
          recordButton.classList.replace("bg-red-500", "bg-purple-500");
          recordButton.classList.replace(
            "hover:bg-red-600",
            "hover:bg-purple-600"
          );
          downloadButton.disabled = false;
          downloadPromptsBtn.disabled = false;
        }
      });

      document
        .getElementById("downloadButton")
        .addEventListener("click", () => {
          const dataStr = JSON.stringify(recordedPoses, null, 2);
          const blob = new Blob([dataStr], { type: "application/json" });
          const url = URL.createObjectURL(blob);
          const a = document.createElement("a");
          a.href = url;
          a.download = `pose_analysis_${new Date().toISOString()}.json`;
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
        });

      document
        .getElementById("downloadPromptsBtn")
        .addEventListener("click", () => {
          downloadPrompts();
        });

      // Add a function to download prompts
      function downloadPrompts() {
        const dataStr = JSON.stringify(savedPrompts, null, 2);
        const blob = new Blob([dataStr], { type: "application/json" });
        const url = URL.createObjectURL(blob);
        const a = document.createElement("a");
        a.href = url;
        a.download = `heygen_prompts_${new Date().toISOString()}.json`;
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
      }

      // Add this new function
      async function requestCameraPermission() {
        try {
          cameraStream = await navigator.mediaDevices.getUserMedia({
            video: {
              facingMode: "user",
              width: { ideal: 1280 },
              height: { ideal: 720 },
            },
          });

          // Hide the camera permission button once we have access
          document.getElementById("cameraPermissionBtn").style.display = "none";

          // Enable the start button
          document.getElementById("startBtn").disabled = false;

          updateStatus("Camera permission granted");
          return true;
        } catch (err) {
          console.error("Camera permission error:", err);
          updateStatus(`Failed to get camera permission: ${err.message}`);
          return false;
        }
      }

      // Add camera permission button event listener
      document
        .getElementById("cameraPermissionBtn")
        .addEventListener("click", requestCameraPermission);

      // Initially disable the start button until camera permission is granted
      document.getElementById("startBtn").disabled = true;

      // Update the getClaudeResponse function
      async function getClaudeResponse(prompt) {
        try {
          const response = await fetch("http://localhost:4000/api/claude", {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
            },
            body: JSON.stringify({
              prompt: prompt,
            }),
          });

          if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
          }

          const data = await response.json();
          console.log("Claude response:", data);
          return data.content[0].text;
        } catch (error) {
          console.error("Claude API error:", error);
          updateStatus(`Claude API error: ${error.message}`);
          return null;
        }
      }
    </script>
  </body>
</html>
