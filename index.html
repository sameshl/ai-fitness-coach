<!DOCTYPE html>
<html lang="en">
  <head>
    <title>HeyGen Streaming API LiveKit (V2)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/livekit-client/dist/livekit-client.umd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <style>
      .video-container {
        position: relative;
        display: block;
        margin-bottom: 10px;
      }
      .pose-canvas {
        position: absolute;
        top: 0;
        left: 0;
        z-index: 10;
      }

      /* Make sure inputs and buttons stack nicely on mobile */
      @media (max-width: 768px) {
        .flex-wrap > * {
          min-width: 100%;
        }
      }
    </style>
  </head>

  <body class="bg-gray-100 p-5 font-sans">
    <div class="max-w-3xl mx-auto bg-white p-5 rounded-lg shadow-md">
      <div class="flex flex-wrap gap-2.5 mb-5">
        <input
          id="avatarID"
          type="text"
          placeholder="Avatar ID"
          class="flex-1 min-w-[200px] p-2 border border-gray-300 rounded-md"
        />
        <input
          id="voiceID"
          type="text"
          placeholder="Voice ID"
          class="flex-1 min-w-[200px] p-2 border border-gray-300 rounded-md"
        />
        <button
          id="startBtn"
          class="px-4 py-2 bg-green-500 text-white rounded-md hover:bg-green-600 transition-colors disabled:opacity-50 disabled:cursor-not-allowed"
        >
          Start
        </button>
        <button
          id="closeBtn"
          class="px-4 py-2 bg-red-500 text-white rounded-md hover:bg-red-600 transition-colors"
        >
          Close
        </button>
      </div>

      <div class="flex flex-wrap gap-2.5 mb-5">
        <input
          id="taskInput"
          type="text"
          placeholder="Enter text for avatar to speak"
          class="flex-1 min-w-[200px] p-2 border border-gray-300 rounded-md"
        />
        <button
          id="talkBtn"
          class="px-4 py-2 bg-green-500 text-white rounded-md hover:bg-green-600 transition-colors"
        >
          Talk (LLM)
        </button>
        <button
          id="repeatBtn"
          class="px-4 py-2 bg-blue-500 text-white rounded-md hover:bg-blue-600 transition-colors"
        >
          Repeat
        </button>
      </div>

      <div class="flex flex-col md:flex-row gap-4 mb-5">
        <div class="video-container w-full md:w-1/2">
          <video
            id="mediaElement"
            class="w-full aspect-video border rounded-lg"
            autoplay
          ></video>
        </div>

        <div class="video-container w-full md:w-1/2">
          <video
            id="poseVideo"
            class="w-full aspect-video border rounded-lg"
            autoplay
          ></video>
          <canvas id="poseCanvas" class="pose-canvas w-full h-full"></canvas>
        </div>
      </div>
      <div
        id="status"
        class="p-2.5 bg-gray-50 border border-gray-300 rounded-md h-[100px] overflow-y-auto font-mono text-sm"
      ></div>

      <div class="flex gap-2 mt-4">
        <button
          id="recordButton"
          class="px-4 py-2 bg-purple-500 text-white rounded-md hover:bg-purple-600 transition-colors hidden"
        >
          Start Recording
        </button>
        <button
          id="downloadButton"
          class="px-4 py-2 bg-gray-500 text-white rounded-md hover:bg-gray-600 transition-colors hidden"
          disabled
        >
          Download Recording
        </button>
      </div>
    </div>

    <script>
      // Configuration
      const API_CONFIG = {
        apiKey: "NTRiOTVmYmFiYTVmNDIxM2E5ZjkyZDcyNDI5ZWQzM2ItMTczNzc5NTY1Ng==",
        serverUrl: "https://api.heygen.com",
      };

      // Global variables
      let sessionInfo = null;
      let room = null;
      let mediaStream = null;
      let webSocket = null;
      let sessionToken = null;
      let poseDetector = null;
      let poseVideo = null;
      let poseCanvas = null;
      let poseCtx = null;
      let isRecording = false;
      let recordedPoses = [];
      let lastRecordedTime = 0;
      let exerciseBuffer = [];
      const BUFFER_SIZE = 3;

      // DOM Elements
      const statusElement = document.getElementById("status");
      const mediaElement = document.getElementById("mediaElement");
      const avatarID = document.getElementById("avatarID");
      const voiceID = document.getElementById("voiceID");
      const taskInput = document.getElementById("taskInput");

      // Helper function to update status
      function updateStatus(message) {
        const timestamp = new Date().toLocaleTimeString();
        statusElement.innerHTML += `[${timestamp}] ${message}<br>`;
        statusElement.scrollTop = statusElement.scrollHeight;
      }

      // Get session token
      async function getSessionToken() {
        const response = await fetch(
          `${API_CONFIG.serverUrl}/v1/streaming.create_token`,
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              "X-Api-Key": API_CONFIG.apiKey,
            },
          }
        );

        const data = await response.json();
        sessionToken = data.data.token;
        updateStatus("Session token obtained");
      }

      // Connect WebSocket
      async function connectWebSocket(sessionId) {
        const params = new URLSearchParams({
          session_id: sessionId,
          session_token: sessionToken,
          silence_response: false,
          opening_text: "Hello, how can I help you?",
          stt_language: "en",
        });

        const wsUrl = `wss://${
          new URL(API_CONFIG.serverUrl).hostname
        }/v1/ws/streaming.chat?${params}`;

        webSocket = new WebSocket(wsUrl);

        // Handle WebSocket events
        webSocket.addEventListener("message", (event) => {
          const eventData = JSON.parse(event.data);
          console.log("Raw WebSocket event:", eventData);
        });
      }

      // Create new session
      async function createNewSession() {
        if (!sessionToken) {
          await getSessionToken();
        }

        const response = await fetch(
          `${API_CONFIG.serverUrl}/v1/streaming.new`,
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${sessionToken}`,
            },
            body: JSON.stringify({
              quality: "high",
              avatar_name: avatarID.value,
              voice: {
                voice_id: voiceID.value,
                rate: 2,
              },
              version: "v2",
              video_encoding: "H264",
            }),
          }
        );

        const data = await response.json();
        sessionInfo = data.data;

        // Create LiveKit Room
        room = new LivekitClient.Room({
          adaptiveStream: true,
          dynacast: true,
          videoCaptureDefaults: {
            resolution: LivekitClient.VideoPresets.h720.resolution,
          },
        });

        // Handle room events
        room.on(LivekitClient.RoomEvent.DataReceived, (message) => {
          const data = new TextDecoder().decode(message);
          console.log("Room message:", JSON.parse(data));
        });

        // Handle media streams
        mediaStream = new MediaStream();
        room.on(LivekitClient.RoomEvent.TrackSubscribed, (track) => {
          if (track.kind === "video" || track.kind === "audio") {
            mediaStream.addTrack(track.mediaStreamTrack);
            if (
              mediaStream.getVideoTracks().length > 0 &&
              mediaStream.getAudioTracks().length > 0
            ) {
              mediaElement.srcObject = mediaStream;
              updateStatus("Media stream ready");
            }
          }
        });

        // Handle media stream removal
        room.on(LivekitClient.RoomEvent.TrackUnsubscribed, (track) => {
          const mediaTrack = track.mediaStreamTrack;
          if (mediaTrack) {
            mediaStream.removeTrack(mediaTrack);
          }
        });

        // Handle room connection state changes
        room.on(LivekitClient.RoomEvent.Disconnected, (reason) => {
          updateStatus(`Room disconnected: ${reason}`);
        });

        await room.prepareConnection(sessionInfo.url, sessionInfo.access_token);
        updateStatus("Connection prepared");

        // Connect WebSocket after room preparation
        await connectWebSocket(sessionInfo.session_id);

        updateStatus("Session created successfully");
      }

      // Start streaming session
      async function startStreamingSession() {
        try {
          // Check camera permissions first
          const hasPermission = await checkCameraPermissions();
          if (!hasPermission) {
            updateStatus(
              "Camera permission denied. Please grant camera access and try again."
            );
            return;
          }

          // Initialize pose detection first
          await initPoseDetection();

          // Then start HeyGen stream
          const startResponse = await fetch(
            `${API_CONFIG.serverUrl}/v1/streaming.start`,
            {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
                Authorization: `Bearer ${sessionToken}`,
              },
              body: JSON.stringify({
                session_id: sessionInfo.session_id,
              }),
            }
          );

          await room.connect(sessionInfo.url, sessionInfo.access_token);
          updateStatus("Connected to room");

          document.querySelector("#startBtn").disabled = true;
          updateStatus("Streaming started successfully");
          showRecordingButtons();
        } catch (error) {
          updateStatus(`Error starting session: ${error.message}`);
          console.error("Session start error:", error);
        }
      }

      // Send text to avatar
      async function sendText(text, taskType = "talk") {
        if (!sessionInfo) {
          updateStatus("No active session");
          return;
        }

        const response = await fetch(
          `${API_CONFIG.serverUrl}/v1/streaming.task`,
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${sessionToken}`,
            },
            body: JSON.stringify({
              session_id: sessionInfo.session_id,
              text: text,
              task_type: taskType,
            }),
          }
        );

        updateStatus(`Sent text (${taskType}): ${text}`);
      }

      // Close session
      async function closeSession() {
        if (!sessionInfo) {
          updateStatus("No active session");
          return;
        }

        const response = await fetch(
          `${API_CONFIG.serverUrl}/v1/streaming.stop`,
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${sessionToken}`,
            },
            body: JSON.stringify({
              session_id: sessionInfo.session_id,
            }),
          }
        );

        // Close WebSocket
        if (webSocket) {
          webSocket.close();
        }
        // Disconnect from LiveKit room
        if (room) {
          room.disconnect();
        }

        mediaElement.srcObject = null;
        sessionInfo = null;
        room = null;
        mediaStream = null;
        sessionToken = null;
        document.querySelector("#startBtn").disabled = false;

        updateStatus("Session closed");
      }

      // Event Listeners
      document
        .querySelector("#startBtn")
        .addEventListener("click", async () => {
          try {
            await createNewSession();
            await startStreamingSession();
          } catch (error) {
            updateStatus(`Failed to start session: ${error.message}`);
            console.error("Start session error:", error);
          }
        });
      document
        .querySelector("#closeBtn")
        .addEventListener("click", closeSession);
      document.querySelector("#talkBtn").addEventListener("click", () => {
        const text = taskInput.value.trim();
        if (text) {
          sendText(text, "talk");
          taskInput.value = "";
        }
      });
      document.querySelector("#repeatBtn").addEventListener("click", () => {
        const text = taskInput.value.trim();
        if (text) {
          sendText(text, "repeat");
          taskInput.value = "";
        }
      });

      // Add these functions before the event listeners
      async function initPoseDetection() {
        poseVideo = document.getElementById("poseVideo");
        poseCanvas = document.getElementById("poseCanvas");
        poseCtx = poseCanvas.getContext("2d");

        // Set canvas size to match video container
        const resizeCanvas = () => {
          poseCanvas.width = poseVideo.clientWidth;
          poseCanvas.height = poseVideo.clientHeight;
        };

        // Initial resize
        resizeCanvas();

        // Resize canvas when window resizes
        window.addEventListener("resize", resizeCanvas);

        try {
          // Check if mediaDevices is supported
          if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            // Fallback for older browsers
            const getUserMedia =
              navigator.getUserMedia ||
              navigator.webkitGetUserMedia ||
              navigator.mozGetUserMedia ||
              navigator.msGetUserMedia;

            if (!getUserMedia) {
              throw new Error("getUserMedia is not supported in this browser");
            }
          }

          const constraints = {
            video: {
              facingMode: "user", // Use front camera for mobile
              width: { ideal: 1280 },
              height: { ideal: 720 },
            },
          };

          const stream = await navigator.mediaDevices.getUserMedia(constraints);
          poseVideo.srcObject = stream;
          await new Promise((resolve) => {
            poseVideo.onloadedmetadata = () => {
              resolve();
            };
          });
          await poseVideo.play();

          poseDetector = await poseDetection.createDetector(
            poseDetection.SupportedModels.MoveNet
          );

          detectPose();
        } catch (error) {
          console.error("Error accessing camera:", error);
          updateStatus(
            `Camera error: ${error.message}. Please ensure camera permissions are granted.`
          );
        }
      }

      // Update the checkCameraPermissions function to be more robust
      async function checkCameraPermissions() {
        try {
          // First check if permissions are already granted
          const permissions = await navigator.permissions.query({
            name: "camera",
          });
          if (permissions.state === "granted") {
            return true;
          }

          // If not granted, request them
          const stream = await navigator.mediaDevices.getUserMedia({
            video: {
              facingMode: "user",
              width: { ideal: 1280 },
              height: { ideal: 720 },
            },
          });

          // Clean up the test stream
          stream.getTracks().forEach((track) => track.stop());
          return true;
        } catch (err) {
          console.error("Camera permission error:", err);
          return false;
        }
      }

      function getAngleBetweenPoints(a, b, c) {
        const vectorAB = {
          x: b.x - a.x,
          y: b.y - a.y,
        };
        const vectorBC = {
          x: c.x - b.x,
          y: c.y - b.y,
        };

        const dotProduct = vectorAB.x * vectorBC.x + vectorAB.y * vectorBC.y;
        const magnitudeAB = Math.sqrt(
          vectorAB.x * vectorAB.x + vectorAB.y * vectorAB.y
        );
        const magnitudeBC = Math.sqrt(
          vectorBC.x * vectorBC.x + vectorBC.y * vectorBC.y
        );
        const angleRadians = Math.acos(
          dotProduct / (magnitudeAB * magnitudeBC)
        );
        return 180 - (angleRadians * 180) / Math.PI;
      }

      async function analyzePose(poses) {
        if (!poses.length) return null;

        const pose = poses[0];
        const kp = Object.fromEntries(
          pose.keypoints.filter((k) => k.score > 0.5).map((k) => [k.name, k])
        );

        const angles = {};
        const analysis = {};

        // Calculate joint angles
        if (kp.right_hip && kp.right_knee && kp.right_ankle) {
          angles.rightKnee = getAngleBetweenPoints(
            kp.right_hip,
            kp.right_knee,
            kp.right_ankle
          );
        }
        if (kp.left_hip && kp.left_knee && kp.left_ankle) {
          angles.leftKnee = getAngleBetweenPoints(
            kp.left_hip,
            kp.left_knee,
            kp.left_ankle
          );
        }
        if (kp.right_shoulder && kp.right_elbow && kp.right_wrist) {
          angles.rightElbow = getAngleBetweenPoints(
            kp.right_shoulder,
            kp.right_elbow,
            kp.right_wrist
          );
        }
        if (kp.left_shoulder && kp.left_elbow && kp.left_wrist) {
          angles.leftElbow = getAngleBetweenPoints(
            kp.left_shoulder,
            kp.left_elbow,
            kp.left_wrist
          );
        }

        // Spine analysis
        if (
          kp.nose &&
          kp.left_shoulder &&
          kp.right_shoulder &&
          kp.left_hip &&
          kp.right_hip
        ) {
          const shoulderMidpoint = {
            x: (kp.left_shoulder.x + kp.right_shoulder.x) / 2,
            y: (kp.left_shoulder.y + kp.right_shoulder.y) / 2,
          };
          const hipMidpoint = {
            x: (kp.left_hip.x + kp.right_hip.x) / 2,
            y: (kp.left_hip.y + kp.right_hip.y) / 2,
          };

          angles.torso =
            Math.atan2(
              shoulderMidpoint.y - hipMidpoint.y,
              shoulderMidpoint.x - hipMidpoint.x
            ) *
            (180 / Math.PI);

          analysis.spine = {
            forward_angle: angles.torso,
            lateral_deviation: shoulderMidpoint.x - hipMidpoint.x,
            head_offset: kp.nose.x - shoulderMidpoint.x,
          };
        }

        // Add relative heights
        if (kp.nose && kp.left_shoulder && kp.right_shoulder) {
          analysis.heights = {
            head_to_shoulder:
              kp.nose.y - (kp.left_shoulder.y + kp.right_shoulder.y) / 2,
            shoulder_to_hip:
              kp.left_shoulder && kp.left_hip
                ? Math.abs(kp.left_shoulder.y - kp.left_hip.y)
                : null,
            hip_to_ankle:
              kp.left_hip && kp.left_ankle
                ? Math.abs(kp.left_hip.y - kp.left_ankle.y)
                : null,
          };
        }

        return {
          timestamp: Date.now(),
          angles,
          analysis,
          keypoints: Object.entries(kp).map(([name, point]) => ({
            name,
            x: point.x,
            y: point.y,
          })),
        };
      }

      // Modify the detectPose function to include recording logic
      async function detectPose() {
        if (!poseDetector) return;

        const poses = await poseDetector.estimatePoses(poseVideo);

        poseCtx.clearRect(0, 0, poseCanvas.width, poseCanvas.height);

        poses.forEach((pose) => {
          // Draw keypoints
          pose.keypoints.forEach((keypoint) => {
            if (keypoint.score > 0.5) {
              poseCtx.beginPath();
              poseCtx.arc(
                (keypoint.x * poseCanvas.width) / poseVideo.videoWidth,
                (keypoint.y * poseCanvas.height) / poseVideo.videoHeight,
                5,
                0,
                2 * Math.PI
              );
              poseCtx.fillStyle = "red";
              poseCtx.fill();
            }
          });

          // Draw skeleton
          const connections = [
            ["left_shoulder", "right_shoulder"],
            ["left_hip", "right_hip"],
            ["left_shoulder", "left_hip"],
            ["right_shoulder", "right_hip"],
            ["left_shoulder", "left_elbow"],
            ["right_shoulder", "right_elbow"],
            ["left_elbow", "left_wrist"],
            ["right_elbow", "right_wrist"],
            ["left_hip", "left_knee"],
            ["right_hip", "right_knee"],
            ["left_knee", "left_ankle"],
            ["right_knee", "right_ankle"],
          ];

          poseCtx.strokeStyle = "blue";
          poseCtx.lineWidth = 2;

          connections.forEach(([from, to]) => {
            const fromPoint = pose.keypoints.find((kp) => kp.name === from);
            const toPoint = pose.keypoints.find((kp) => kp.name === to);

            if (
              fromPoint &&
              toPoint &&
              fromPoint.score > 0.5 &&
              toPoint.score > 0.5
            ) {
              poseCtx.beginPath();
              poseCtx.moveTo(
                (fromPoint.x * poseCanvas.width) / poseVideo.videoWidth,
                (fromPoint.y * poseCanvas.height) / poseVideo.videoHeight
              );
              poseCtx.lineTo(
                (toPoint.x * poseCanvas.width) / poseVideo.videoWidth,
                (toPoint.y * poseCanvas.height) / poseVideo.videoHeight
              );
              poseCtx.stroke();
            }
          });
        });

        if (isRecording) {
          const currentTime = Date.now();
          if (currentTime - lastRecordedTime >= 200) {
            const analysis = await analyzePose(poses);
            if (analysis) {
              recordedPoses.push(analysis);

              // Send last 10 frames (2 seconds worth at 5fps) of data to LLM every 2 seconds
              if (recordedPoses.length % 10 === 0) {
                const last10Frames = recordedPoses.slice(-10);
                const prompt = `You are an expert fitness coach watching someone exercise. Be motivating in your feedback. Analyze their movement patterns over the last 2 seconds and provide specific, actionable feedback. The user is trying to do a pushup. Focus on form issues and improvements needed. Keep feedback concise, 3 words max. If there is no feedback or not enough data, just say something encouraging.

Here's the sequence of pose data:

${last10Frames
  .map(
    (frame, i) => `
Timeframe ${i + 1}:
Angles:
- Left knee: ${frame.angles.leftKnee?.toFixed(1)}°
- Right knee: ${frame.angles.rightKnee?.toFixed(1)}°
- Left elbow: ${frame.angles.leftElbow?.toFixed(1)}°
- Right elbow: ${frame.angles.rightElbow?.toFixed(1)}°
- Torso angle: ${frame.angles.torso?.toFixed(1)}°

Spine:
- Forward lean: ${frame.analysis.spine?.forward_angle?.toFixed(1)}°
- Side lean: ${frame.analysis.spine?.lateral_deviation?.toFixed(1)}
- Head position offset: ${frame.analysis.spine?.head_offset?.toFixed(1)}

Heights:
- Head to shoulder: ${frame.analysis.heights?.head_to_shoulder?.toFixed(1)}
- Shoulder to hip: ${frame.analysis.heights?.shoulder_to_hip?.toFixed(1)}
- Hip to ankle: ${frame.analysis.heights?.hip_to_ankle?.toFixed(1)}
`
  )
  .join("\n")}

Based on these movement patterns, what one liner feedback would you give?`;

                await sendText(prompt, "talk");
              }

              lastRecordedTime = currentTime;
            }
          }
        }

        requestAnimationFrame(detectPose);
      }

      // Add these to your existing startStreamingSession function
      function showRecordingButtons() {
        document.getElementById("recordButton").classList.remove("hidden");
        document.getElementById("downloadButton").classList.remove("hidden");
      }

      // Add these event listeners
      document.getElementById("recordButton").addEventListener("click", () => {
        isRecording = !isRecording;
        const recordButton = document.getElementById("recordButton");
        const downloadButton = document.getElementById("downloadButton");

        if (isRecording) {
          recordButton.textContent = "Stop Recording";
          recordButton.classList.replace("bg-purple-500", "bg-red-500");
          recordButton.classList.replace(
            "hover:bg-purple-600",
            "hover:bg-red-600"
          );
          downloadButton.disabled = true;
          recordedPoses = [];
        } else {
          recordButton.textContent = "Start Recording";
          recordButton.classList.replace("bg-red-500", "bg-purple-500");
          recordButton.classList.replace(
            "hover:bg-red-600",
            "hover:bg-purple-600"
          );
          downloadButton.disabled = false;
        }
      });

      document
        .getElementById("downloadButton")
        .addEventListener("click", () => {
          const dataStr = JSON.stringify(recordedPoses, null, 2);
          const blob = new Blob([dataStr], { type: "application/json" });
          const url = URL.createObjectURL(blob);
          const a = document.createElement("a");
          a.href = url;
          a.download = `pose_analysis_${new Date().toISOString()}.json`;
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
        });
    </script>
  </body>
</html>
